{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4YPukIVDJI0"
      },
      "outputs": [],
      "source": [
        "# general libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import json\n",
        "\n",
        "# ml algorithms/tools\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaGZlKWXB8RR",
        "outputId": "01f8bb96-1d44-463e-909e-acb71fd4921e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jmggw9NsDi-Z"
      },
      "outputs": [],
      "source": [
        "#gathering data\n",
        "labels_data_frame = pd.read_csv('/content/drive/MyDrive/Research/ML Research/SummerMLProject/twitter_suicide_data.csv')\n",
        "labels = labels_data_frame[\"intention\"].values\n",
        "\n",
        "features_data_frame = pd.read_csv('/content/drive/MyDrive/Research/ML Research/SummerMLProject/features.csv')\n",
        "features = features_data_frame[[\"suicidal\",\"non-suicidal\", \"length\"]].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFk-lC9ADp7d"
      },
      "outputs": [],
      "source": [
        "# splitting into training and validation set\n",
        "x_training, x_validation, y_training, y_validation = train_test_split(features, labels, test_size = 0.25, random_state = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVC7F8FjDqeU",
        "outputId": "1d70dae9-3b59-47d2-fea1-abca5238c2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:  12106.071257981186\n",
            "Standard deviation:  35733.149540385304\n"
          ]
        }
      ],
      "source": [
        "# scaling the features using a standard scaler\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(x_training)\n",
        "x_training_scaled = scaler.transform(x_training)\n",
        "x_validation_scaled = scaler.transform(x_validation)\n",
        "print(\"Mean: \", np.mean(x_training))\n",
        "print(\"Standard deviation: \", np.std(x_training))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2iXA3GtiZUs"
      },
      "outputs": [],
      "source": [
        "# scaling the features using a min-max scaler\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "scaler.fit(x_training)\n",
        "x_training_scaled = scaler.transform(x_training)\n",
        "x_validation_scaled = scaler.transform(x_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qTnSU_gegQQ",
        "outputId": "0bad947d-0d15-43db-b6a0-b0c55f210e3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# creating the logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(x_training_scaled, y_training)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating accuracy on training set\n",
        "y_training_hat_cat = 1*(model.predict(x_training_scaled) > 0.5)\n",
        "print(classification_report(y_training, y_training_hat_cat))\n",
        "\n",
        "# caluclating accuray on valdiation set\n",
        "y_validation_hat_cat = 1*(model.predict(x_validation_scaled) > 0.5)\n",
        "print(classification_report(y_validation, y_validation_hat_cat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iHW-mIg7NP",
        "outputId": "27bb20d4-0824-460a-e9cc-eb196751ccac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.97      0.87      3824\n",
            "           1       0.95      0.68      0.79      3015\n",
            "\n",
            "    accuracy                           0.84      6839\n",
            "   macro avg       0.87      0.82      0.83      6839\n",
            "weighted avg       0.86      0.84      0.84      6839\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.97      0.87      1297\n",
            "           1       0.94      0.66      0.77       983\n",
            "\n",
            "    accuracy                           0.84      2280\n",
            "   macro avg       0.87      0.81      0.82      2280\n",
            "weighted avg       0.86      0.84      0.83      2280\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBxd5QNde5Iy",
        "outputId": "04e3cc47-0c57-4633-cdbe-43cd754e8344"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# creating the decision tree model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(x_training_scaled, y_training)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating accuracy on training set\n",
        "y_training_hat_cat = 1*(model.predict(x_training_scaled) > 0.5)\n",
        "print(classification_report(y_training, y_training_hat_cat))\n",
        "\n",
        "# caluclating accuray on valdiation set\n",
        "y_validation_hat_cat = 1*(model.predict(x_validation_scaled) > 0.5)\n",
        "print(classification_report(y_validation, y_validation_hat_cat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dwDrxASg6gh",
        "outputId": "2cf82872-1f10-4359-b490-2aca03b49bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3824\n",
            "           1       1.00      1.00      1.00      3015\n",
            "\n",
            "    accuracy                           1.00      6839\n",
            "   macro avg       1.00      1.00      1.00      6839\n",
            "weighted avg       1.00      1.00      1.00      6839\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.89      1297\n",
            "           1       0.86      0.86      0.86       983\n",
            "\n",
            "    accuracy                           0.88      2280\n",
            "   macro avg       0.88      0.88      0.88      2280\n",
            "weighted avg       0.88      0.88      0.88      2280\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDNbQn4HomkH",
        "outputId": "453d99f4-4690-4b60-9131-24ac2162679f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# creating a support vector machine model\n",
        "from sklearn.svm import SVC\n",
        "model = SVC()\n",
        "model.fit(x_training_scaled, y_training)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating accuracy on training set\n",
        "y_training_hat_cat = 1*(model.predict(x_training_scaled) > 0.5)\n",
        "print(classification_report(y_training, y_training_hat_cat))\n",
        "\n",
        "# caluclating accuray on valdiation set\n",
        "y_validation_hat_cat = 1*(model.predict(x_validation_scaled) > 0.5)\n",
        "print(classification_report(y_validation, y_validation_hat_cat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPv6tVbOg5zQ",
        "outputId": "833073ff-6d1f-420c-c075-c3ed14b4c820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93      3824\n",
            "           1       0.99      0.82      0.90      3015\n",
            "\n",
            "    accuracy                           0.92      6839\n",
            "   macro avg       0.93      0.91      0.92      6839\n",
            "weighted avg       0.93      0.92      0.92      6839\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93      1297\n",
            "           1       0.98      0.82      0.90       983\n",
            "\n",
            "    accuracy                           0.92      2280\n",
            "   macro avg       0.93      0.91      0.91      2280\n",
            "weighted avg       0.92      0.92      0.92      2280\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "OJYxgc2ufeJR",
        "outputId": "4891b0ba-e38e-4095-da4f-a7b3f6133211"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3f2823cb71ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# creating a naive bayes model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_training_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
          ]
        }
      ],
      "source": [
        "# creating a naive bayes model\n",
        "model = MultinomialNB()\n",
        "model.fit(x_training_scaled, y_training)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating accuracy on training set\n",
        "y_training_hat_cat = 1*(model.predict(x_training_scaled) > 0.5)\n",
        "print(classification_report(y_training, y_training_hat_cat))\n",
        "\n",
        "# caluclating accuray on valdiation set\n",
        "y_validation_hat_cat = 1*(model.predict(x_validation_scaled) > 0.5)\n",
        "print(classification_report(y_validation, y_validation_hat_cat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OjXy6mMg5BE",
        "outputId": "186f4708-c636-4db5-a4b3-9088d6950476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.72      3824\n",
            "           1       0.00      0.00      0.00      3015\n",
            "\n",
            "    accuracy                           0.56      6839\n",
            "   macro avg       0.28      0.50      0.36      6839\n",
            "weighted avg       0.31      0.56      0.40      6839\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      1.00      0.73      1297\n",
            "           1       0.00      0.00      0.00       983\n",
            "\n",
            "    accuracy                           0.57      2280\n",
            "   macro avg       0.28      0.50      0.36      2280\n",
            "weighted avg       0.32      0.57      0.41      2280\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IvKxNP0f2hI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29293e12-e6cc-442a-e618-892af5d5fa4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# creating a KNN model\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(x_training_scaled, y_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-eoSaxtd3Vh",
        "outputId": "00f7eaee-ca7f-47fa-e4ac-4a094d36af03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      3824\n",
            "           1       0.97      0.89      0.93      3015\n",
            "\n",
            "    accuracy                           0.94      6839\n",
            "   macro avg       0.94      0.93      0.94      6839\n",
            "weighted avg       0.94      0.94      0.94      6839\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93      1297\n",
            "           1       0.94      0.86      0.89       983\n",
            "\n",
            "    accuracy                           0.91      2280\n",
            "   macro avg       0.92      0.91      0.91      2280\n",
            "weighted avg       0.91      0.91      0.91      2280\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# calculating accuracy on training set\n",
        "y_training_hat_cat = 1*(model.predict(x_training_scaled) > 0.5)\n",
        "print(classification_report(y_training, y_training_hat_cat))\n",
        "\n",
        "# caluclating accuray on valdiation set\n",
        "y_validation_hat_cat = 1*(model.predict(x_validation_scaled) > 0.5)\n",
        "print(classification_report(y_validation, y_validation_hat_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpN3Y8WlEbZS"
      },
      "outputs": [],
      "source": [
        "# user input\n",
        "tweet = input(\"Tweet: \")\n",
        "proccessed_tweets = []\n",
        "\n",
        "# tokenizing the tweets\n",
        "tokenizer = TweetTokenizer()  \n",
        "tokenized_list = tokenizer.tokenize(tweet)\n",
        "\n",
        "for i in range(len(tokenized_list)):\n",
        "  proccessed_tweets.append(tokenized_list[i])\n",
        "\n",
        "# removing stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "for i in range(len(proccessed_tweets)):\n",
        "  for n in range(len(stop_words)):\n",
        "    if proccessed_tweets[i] == stop_words[n]:\n",
        "      proccessed_tweets[i] = re.sub(r\"\\b{}\\b\".format(stop_words[n]),\"\", proccessed_tweets[i])\n",
        "\n",
        "# removing punctuation\n",
        "# all standard punctuation has been already removed from the dataset, but emoticons are still present\n",
        "punctuation_string = string.punctuation\n",
        "punctuation = tokenizer.tokenize(punctuation_string)\n",
        "\n",
        "for i in range(len(proccessed_tweets)):\n",
        "  for n in range(len(punctuation)):\n",
        "    if proccessed_tweets[i] == punctuation[n]:\n",
        "      proccessed_tweets[i] = re.sub(r\"\\b{}\\b\".format(punctuation[n]),\"\", proccessed_tweets[i])\n",
        "\n",
        "final_tweet = []\n",
        "\n",
        "# stemming words\n",
        "stemmer = PorterStemmer()\n",
        "for i in range(len(proccessed_tweets)):\n",
        "  pre_stemmed = proccessed_tweets[i]\n",
        "  stemmed_word = stemmer.stem(pre_stemmed)\n",
        "  final_tweet.append(stemmed_word)\n",
        "  \n",
        "# removing white spaces\n",
        "blank = 0\n",
        "for i in range(len(final_tweet)):\n",
        "  if final_tweet[i] == \"\":\n",
        "    blank += 1\n",
        "\n",
        "for i in range(blank):\n",
        "  final_tweet.remove(\"\")\n",
        "\n",
        "# turning features JSON file into dictionary\n",
        "with open('/content/drive/MyDrive/Research/ML Research/SummerMLProject/frequency.json') as json_file:\n",
        "  frequency = json.load(json_file)\n",
        "\n",
        "total_suicidal_value = 0\n",
        "total_non_suicidal_value = 0\n",
        "\n",
        "for word in final_tweet:\n",
        "\n",
        "  suicidal_value = 0\n",
        "  non_suicidal_value = 0\n",
        "\n",
        "  suicidal_key = word + \" ,1\"\n",
        "  non_suicidal_key = word + \" ,0\"\n",
        "\n",
        "  if suicidal_key in frequency:\n",
        "    suicidal_value = frequency[suicidal_key]\n",
        "  if non_suicidal_key in frequency:\n",
        "    non_suicidal_value = frequency[non_suicidal_key]\n",
        "    \n",
        "  total_suicidal_value += suicidal_value\n",
        "  total_non_suicidal_value += non_suicidal_value\n",
        "\n",
        "features_input = [total_suicidal_value, total_non_suicidal_value, len(tweet)]\n",
        "  \n",
        "features_input = np.array(features_input)\n",
        "features_input = features_input.reshape(-1,3)\n",
        "\n",
        "x_input = scaler.transform(features_input)\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "predicted_output = model.predict(x_input)\n",
        "if predicted_output >= 0.5:\n",
        "  print(\"suicidal, exact probability: \", predicted_output)\n",
        "else:\n",
        "  print(\"non-suicidal, exact probability: \", predicted_output)\n",
        "\n",
        "print()\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5JcxFaTHFCa",
        "outputId": "986fde1f-293c-48db-8e12-84ba99159ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (22.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: coremltools in /usr/local/lib/python3.7/dist-packages (6.1)\n",
            "Requirement already satisfied: protobuf<=4.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools) (3.19.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from coremltools) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.21.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from coremltools) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->coremltools) (3.0.9)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->coremltools) (1.2.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running TensorFlow Graph Passes: 100%|██████████| 6/6 [00:00<00:00, 18.64 passes/s]\n",
            "Converting TF Frontend ==> MIL Ops: 100%|██████████| 7/7 [00:00<00:00, 2237.81 ops/s]\n",
            "Running MIL Common passes: 100%|██████████| 39/39 [00:00<00:00, 1156.01 passes/s]\n",
            "Running MIL Clean up passes: 100%|██████████| 11/11 [00:00<00:00, 2154.14 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 4/4 [00:00<00:00, 9782.63 ops/s]\n"
          ]
        }
      ],
      "source": [
        "# turning into usable file for aplication\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install -U coremltools\n",
        "\n",
        "from coremltools.converters import sklearn as sklearn_to_ml\n",
        "\n",
        "print('Converting model')\n",
        "coreml_model = sklearn_to_ml.convert(model)\n",
        "\n",
        "print('Saving CoreML model')\n",
        "coreml_model.save('suicideDetectionModel.mlmodel')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}